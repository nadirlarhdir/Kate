{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use a Neural Network to predict the players identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the feature data generated by the last year and train the NN with it. After we'll try our new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('kate_data_julien_sarah.csv', delimiter=',')\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.85\n",
    "l = len(data)\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "X_train = X[:int(l*training_ratio)]\n",
    "X_test = X[int(l*training_ratio):]\n",
    "y_train = y[:int(l*training_ratio)]/2\n",
    "y_test = y[int(l*training_ratio):]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.np_utils.to_categorical(y_train.astype(int))\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't understand this part... Just copied. I think they've manually applied the dimension reduction and created this \"error\". If so, we could do that directly using SciKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reconstruction error with 2 PCs: 7.716\n",
      "21.058764803052487\n",
      "-2859.1253240256224\n",
      "107.92906072338096\n",
      "-362.8429742740416\n",
      "17\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "mu = X_train.mean(axis=0)\n",
    "U,s,V = np.linalg.svd(X_train - mu, full_matrices=False)\n",
    "Zpca = np.dot(X_train - mu, V.transpose())\n",
    "\n",
    "Rpca = np.dot(Zpca[:,:2], V[:2,:]) + mu    # reconstruction\n",
    "err = np.sum((X_train-Rpca)**2)/Rpca.shape[0]/Rpca.shape[1]\n",
    "print('PCA reconstruction error with 2 PCs: ' + str(round(err,3)));\n",
    "print(max(Zpca[:,0]))\n",
    "print(min(Zpca[:,0]))\n",
    "print(max(Zpca[:,1]))\n",
    "print(min(Zpca[:,1]))\n",
    "\n",
    "print(np.argmax(Zpca[:,0]))\n",
    "print(np.argmax(Zpca[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training of a dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1360 samples, validate on 240 samples\n",
      "Epoch 1/128\n",
      "1360/1360 [==============================] - 5s 4ms/step - loss: nan - acc: 0.6441 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 2/128\n",
      "1360/1360 [==============================] - 1s 475us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 3/128\n",
      "1360/1360 [==============================] - 1s 451us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 4/128\n",
      "1360/1360 [==============================] - 1s 473us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 5/128\n",
      "1360/1360 [==============================] - 1s 476us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 6/128\n",
      "1360/1360 [==============================] - 1s 481us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 7/128\n",
      "1360/1360 [==============================] - 1s 527us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 8/128\n",
      "1360/1360 [==============================] - 1s 513us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 9/128\n",
      "1360/1360 [==============================] - 1s 542us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 10/128\n",
      "1360/1360 [==============================] - 1s 469us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 11/128\n",
      "1360/1360 [==============================] - 1s 465us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 12/128\n",
      "1360/1360 [==============================] - 1s 482us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 13/128\n",
      "1360/1360 [==============================] - 1s 474us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 14/128\n",
      "1360/1360 [==============================] - 1s 562us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 15/128\n",
      "1360/1360 [==============================] - 1s 527us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 16/128\n",
      "1360/1360 [==============================] - 1s 495us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 17/128\n",
      "1360/1360 [==============================] - 1s 525us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 18/128\n",
      "1360/1360 [==============================] - 1s 548us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 19/128\n",
      "1360/1360 [==============================] - 1s 688us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 20/128\n",
      "1360/1360 [==============================] - 1s 505us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 21/128\n",
      "1360/1360 [==============================] - 1s 594us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 22/128\n",
      "1360/1360 [==============================] - 1s 517us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 23/128\n",
      "1360/1360 [==============================] - 1s 577us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 24/128\n",
      "1360/1360 [==============================] - 1s 560us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 25/128\n",
      "1360/1360 [==============================] - 1s 749us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 26/128\n",
      "1360/1360 [==============================] - 1s 551us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 27/128\n",
      "1360/1360 [==============================] - 1s 564us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 28/128\n",
      "1360/1360 [==============================] - 1s 568us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 29/128\n",
      "1360/1360 [==============================] - 1s 582us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 30/128\n",
      "1360/1360 [==============================] - 1s 629us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 31/128\n",
      "1360/1360 [==============================] - 1s 553us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 32/128\n",
      "1360/1360 [==============================] - 1s 565us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 33/128\n",
      "1360/1360 [==============================] - 1s 501us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 34/128\n",
      "1360/1360 [==============================] - 1s 515us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 35/128\n",
      "1360/1360 [==============================] - 1s 512us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 36/128\n",
      "1360/1360 [==============================] - 1s 487us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 37/128\n",
      "1360/1360 [==============================] - 1s 596us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 38/128\n",
      "1360/1360 [==============================] - 1s 586us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 39/128\n",
      "1360/1360 [==============================] - 1s 605us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 40/128\n",
      "1360/1360 [==============================] - 1s 554us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 41/128\n",
      "1360/1360 [==============================] - 1s 529us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 42/128\n",
      "1360/1360 [==============================] - 1s 530us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 43/128\n",
      "1360/1360 [==============================] - 1s 478us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 44/128\n",
      "1360/1360 [==============================] - 1s 520us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 45/128\n",
      "1360/1360 [==============================] - 1s 516us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 46/128\n",
      "1360/1360 [==============================] - 1s 481us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 47/128\n",
      "1360/1360 [==============================] - 1s 533us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 48/128\n",
      "1360/1360 [==============================] - 1s 578us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 49/128\n",
      "1360/1360 [==============================] - ETA: 0s - loss: nan - acc: 0.50 - 1s 537us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 50/128\n",
      "1360/1360 [==============================] - 1s 471us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 51/128\n",
      "1360/1360 [==============================] - 1s 472us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 52/128\n",
      "1360/1360 [==============================] - 1s 458us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 53/128\n",
      "1360/1360 [==============================] - 1s 452us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 54/128\n",
      "1360/1360 [==============================] - 1s 504us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 55/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 56/128\n",
      "1360/1360 [==============================] - 1s 461us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 57/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 58/128\n",
      "1360/1360 [==============================] - 1s 468us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 59/128\n",
      "1360/1360 [==============================] - 1s 481us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 60/128\n",
      "1360/1360 [==============================] - 1s 470us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 61/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 62/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360/1360 [==============================] - 1s 533us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 63/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 64/128\n",
      "1360/1360 [==============================] - 1s 451us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 65/128\n",
      "1360/1360 [==============================] - 1s 471us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 66/128\n",
      "1360/1360 [==============================] - 1s 458us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 67/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 68/128\n",
      "1360/1360 [==============================] - 1s 472us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 69/128\n",
      "1360/1360 [==============================] - 1s 474us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 70/128\n",
      "1360/1360 [==============================] - 1s 483us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 71/128\n",
      "1360/1360 [==============================] - 1s 481us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 72/128\n",
      "1360/1360 [==============================] - 1s 470us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 73/128\n",
      "1360/1360 [==============================] - 1s 447us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 74/128\n",
      "1360/1360 [==============================] - 1s 449us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 75/128\n",
      "1360/1360 [==============================] - 1s 465us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 76/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 77/128\n",
      "1360/1360 [==============================] - 1s 481us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 78/128\n",
      "1360/1360 [==============================] - 1s 476us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 79/128\n",
      "1360/1360 [==============================] - 1s 463us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 80/128\n",
      "1360/1360 [==============================] - 1s 570us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 81/128\n",
      "1360/1360 [==============================] - 1s 570us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 82/128\n",
      "1360/1360 [==============================] - 1s 599us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 83/128\n",
      "1360/1360 [==============================] - 1s 526us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 84/128\n",
      "1360/1360 [==============================] - 1s 533us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 85/128\n",
      "1360/1360 [==============================] - 1s 472us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 86/128\n",
      "1360/1360 [==============================] - 1s 471us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 87/128\n",
      "1360/1360 [==============================] - 1s 495us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 88/128\n",
      "1360/1360 [==============================] - 1s 524us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 89/128\n",
      "1360/1360 [==============================] - 1s 573us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 90/128\n",
      "1360/1360 [==============================] - 1s 585us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 91/128\n",
      "1360/1360 [==============================] - 1s 586us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 92/128\n",
      "1360/1360 [==============================] - 1s 512us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 93/128\n",
      "1360/1360 [==============================] - 1s 444us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 94/128\n",
      "1360/1360 [==============================] - 1s 448us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 95/128\n",
      "1360/1360 [==============================] - 1s 469us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 96/128\n",
      "1360/1360 [==============================] - 1s 522us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 97/128\n",
      "1360/1360 [==============================] - 1s 478us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 98/128\n",
      "1360/1360 [==============================] - ETA: 0s - loss: nan - acc: 0.50 - 1s 481us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 99/128\n",
      "1360/1360 [==============================] - 1s 476us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 100/128\n",
      "1360/1360 [==============================] - 1s 491us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 101/128\n",
      "1360/1360 [==============================] - 1s 466us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 102/128\n",
      "1360/1360 [==============================] - 1s 491us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 103/128\n",
      "1360/1360 [==============================] - 1s 581us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 104/128\n",
      "1360/1360 [==============================] - 1s 614us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 105/128\n",
      "1360/1360 [==============================] - 1s 585us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 106/128\n",
      "1360/1360 [==============================] - 1s 502us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 107/128\n",
      "1360/1360 [==============================] - 1s 583us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 108/128\n",
      "1360/1360 [==============================] - 1s 559us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 109/128\n",
      "1360/1360 [==============================] - 1s 488us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 110/128\n",
      "1360/1360 [==============================] - 1s 475us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 111/128\n",
      "1360/1360 [==============================] - 1s 553us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 112/128\n",
      "1360/1360 [==============================] - 1s 491us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 113/128\n",
      "1360/1360 [==============================] - 1s 471us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 114/128\n",
      "1360/1360 [==============================] - 1s 496us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 115/128\n",
      "1360/1360 [==============================] - 1s 531us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 116/128\n",
      "1360/1360 [==============================] - 1s 524us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 117/128\n",
      "1360/1360 [==============================] - 1s 504us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 118/128\n",
      "1360/1360 [==============================] - 1s 512us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 119/128\n",
      "1360/1360 [==============================] - 1s 488us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 120/128\n",
      "1360/1360 [==============================] - 1s 478us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 121/128\n",
      "1360/1360 [==============================] - 1s 494us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 122/128\n",
      "1360/1360 [==============================] - 1s 490us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 123/128\n",
      "1360/1360 [==============================] - 1s 487us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/128\n",
      "1360/1360 [==============================] - 1s 513us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 125/128\n",
      "1360/1360 [==============================] - 1s 565us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 126/128\n",
      "1360/1360 [==============================] - 1s 537us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 127/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n",
      "Epoch 128/128\n",
      "1360/1360 [==============================] - 1s 503us/step - loss: nan - acc: 0.5051 - val_loss: nan - val_acc: 0.4542\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(150,  activation='relu', input_shape=(105,)))\n",
    "#m.add(Dense(150,  activation='relu')) \n",
    "m.add(Dense(150,  activation='relu'))\n",
    "m.add(Dense(150,  activation='relu'))\n",
    "m.add(Dense(50,  activation='relu'))\n",
    "m.add(Dense(2,  activation='sigmoid'))\n",
    "m.compile(loss='categorical_crossentropy', optimizer = Adam(), metrics=['accuracy'])\n",
    "\n",
    "history = m.fit(X_train, y_train, batch_size=10, epochs=128, verbose=1, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = m.fit(X_train, y_train, batch_size=300, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 137us/step\n",
      "Précision old features: 0.45\n"
     ]
    }
   ],
   "source": [
    "accuracy = m.evaluate(X_test, y_test)[1]\n",
    "print(\"Précision old features: %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with ours now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('features_wave_julian_sarah.csv', delimiter=',')\n",
    "y = np.genfromtxt('output_wave_julian_sarah.csv', delimiter=',')\n",
    "\n",
    "p = np.random.permutation(len(X))\n",
    "X, y = X[p], y[p]\n",
    "\n",
    "training_ratio = 0.85\n",
    "l = len(y)\n",
    "X_train = X[:int(l*training_ratio)]\n",
    "X_test = X[int(l*training_ratio):]\n",
    "y_train = y[:int(l*training_ratio)]/2\n",
    "y_test = y[int(l*training_ratio):]/2\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train.astype(int))\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we have 12 dimensions to features instead. Let's apply the NN directly without a PCA to compare later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1360 samples, validate on 240 samples\n",
      "Epoch 1/128\n",
      "1360/1360 [==============================] - 5s 4ms/step - loss: 0.4710 - acc: 0.7654 - val_loss: 0.5346 - val_acc: 0.8000\n",
      "Epoch 2/128\n",
      "1360/1360 [==============================] - 1s 437us/step - loss: 0.4518 - acc: 0.7772 - val_loss: 0.4536 - val_acc: 0.7917\n",
      "Epoch 3/128\n",
      "1360/1360 [==============================] - 1s 431us/step - loss: 0.4216 - acc: 0.7919 - val_loss: 0.4924 - val_acc: 0.7458\n",
      "Epoch 4/128\n",
      "1360/1360 [==============================] - 1s 432us/step - loss: 0.4153 - acc: 0.8007 - val_loss: 0.4587 - val_acc: 0.8000\n",
      "Epoch 5/128\n",
      "1360/1360 [==============================] - 1s 429us/step - loss: 0.3965 - acc: 0.8103 - val_loss: 0.3989 - val_acc: 0.8000\n",
      "Epoch 6/128\n",
      "1360/1360 [==============================] - 1s 477us/step - loss: 0.3821 - acc: 0.8162 - val_loss: 0.4006 - val_acc: 0.8333\n",
      "Epoch 7/128\n",
      "1360/1360 [==============================] - 1s 439us/step - loss: 0.3827 - acc: 0.8235 - val_loss: 0.3660 - val_acc: 0.8375\n",
      "Epoch 8/128\n",
      "1360/1360 [==============================] - 1s 446us/step - loss: 0.3724 - acc: 0.8265 - val_loss: 0.3712 - val_acc: 0.8167\n",
      "Epoch 9/128\n",
      "1360/1360 [==============================] - 1s 435us/step - loss: 0.3608 - acc: 0.8228 - val_loss: 0.3804 - val_acc: 0.8542\n",
      "Epoch 10/128\n",
      "1360/1360 [==============================] - 1s 428us/step - loss: 0.3585 - acc: 0.8390 - val_loss: 0.3792 - val_acc: 0.8333\n",
      "Epoch 11/128\n",
      "1360/1360 [==============================] - 1s 436us/step - loss: 0.3621 - acc: 0.8162 - val_loss: 0.3817 - val_acc: 0.8417\n",
      "Epoch 12/128\n",
      "1360/1360 [==============================] - 1s 470us/step - loss: 0.3505 - acc: 0.8390 - val_loss: 0.3540 - val_acc: 0.8542\n",
      "Epoch 13/128\n",
      "1360/1360 [==============================] - 1s 445us/step - loss: 0.3380 - acc: 0.8478 - val_loss: 0.3610 - val_acc: 0.8417\n",
      "Epoch 14/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.3337 - acc: 0.8360 - val_loss: 0.3601 - val_acc: 0.8542\n",
      "Epoch 15/128\n",
      "1360/1360 [==============================] - 1s 429us/step - loss: 0.3323 - acc: 0.8426 - val_loss: 0.3717 - val_acc: 0.8333\n",
      "Epoch 16/128\n",
      "1360/1360 [==============================] - 1s 439us/step - loss: 0.3277 - acc: 0.8485 - val_loss: 0.3648 - val_acc: 0.8792\n",
      "Epoch 17/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.3343 - acc: 0.8463 - val_loss: 0.3511 - val_acc: 0.8458\n",
      "Epoch 18/128\n",
      "1360/1360 [==============================] - 1s 473us/step - loss: 0.3244 - acc: 0.8456 - val_loss: 0.3712 - val_acc: 0.8375\n",
      "Epoch 19/128\n",
      "1360/1360 [==============================] - 1s 436us/step - loss: 0.3232 - acc: 0.8434 - val_loss: 0.3477 - val_acc: 0.8375\n",
      "Epoch 20/128\n",
      "1360/1360 [==============================] - 1s 431us/step - loss: 0.3256 - acc: 0.8456 - val_loss: 0.4076 - val_acc: 0.8333\n",
      "Epoch 21/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.3035 - acc: 0.8529 - val_loss: 0.2791 - val_acc: 0.8667\n",
      "Epoch 22/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.2903 - acc: 0.8529 - val_loss: 0.3724 - val_acc: 0.8292\n",
      "Epoch 23/128\n",
      "1360/1360 [==============================] - 1s 451us/step - loss: 0.3062 - acc: 0.8515 - val_loss: 0.2857 - val_acc: 0.8333\n",
      "Epoch 24/128\n",
      "1360/1360 [==============================] - 1s 455us/step - loss: 0.3063 - acc: 0.8382 - val_loss: 0.2867 - val_acc: 0.8500\n",
      "Epoch 25/128\n",
      "1360/1360 [==============================] - 1s 431us/step - loss: 0.3105 - acc: 0.8471 - val_loss: 0.3523 - val_acc: 0.8708\n",
      "Epoch 26/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.3149 - acc: 0.8566 - val_loss: 0.3465 - val_acc: 0.8375\n",
      "Epoch 27/128\n",
      "1360/1360 [==============================] - 1s 443us/step - loss: 0.3105 - acc: 0.8485 - val_loss: 0.2935 - val_acc: 0.8792\n",
      "Epoch 28/128\n",
      "1360/1360 [==============================] - 1s 447us/step - loss: 0.3216 - acc: 0.8390 - val_loss: 0.2823 - val_acc: 0.8458\n",
      "Epoch 29/128\n",
      "1360/1360 [==============================] - 1s 450us/step - loss: 0.2915 - acc: 0.8551 - val_loss: 0.3044 - val_acc: 0.8333\n",
      "Epoch 30/128\n",
      "1360/1360 [==============================] - 1s 435us/step - loss: 0.3142 - acc: 0.8434 - val_loss: 0.2982 - val_acc: 0.8500\n",
      "Epoch 31/128\n",
      "1360/1360 [==============================] - 1s 479us/step - loss: 0.2998 - acc: 0.8441 - val_loss: 0.4301 - val_acc: 0.8000\n",
      "Epoch 32/128\n",
      "1360/1360 [==============================] - 1s 479us/step - loss: 0.3005 - acc: 0.8522 - val_loss: 0.3123 - val_acc: 0.8417\n",
      "Epoch 33/128\n",
      "1360/1360 [==============================] - 1s 433us/step - loss: 0.2903 - acc: 0.8500 - val_loss: 0.4106 - val_acc: 0.8000\n",
      "Epoch 34/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.2958 - acc: 0.8456 - val_loss: 0.2964 - val_acc: 0.8667\n",
      "Epoch 35/128\n",
      "1360/1360 [==============================] - 1s 445us/step - loss: 0.2954 - acc: 0.8522 - val_loss: 0.2918 - val_acc: 0.8542\n",
      "Epoch 36/128\n",
      "1360/1360 [==============================] - 1s 484us/step - loss: 0.2856 - acc: 0.8537 - val_loss: 0.2893 - val_acc: 0.8333\n",
      "Epoch 37/128\n",
      "1360/1360 [==============================] - 1s 461us/step - loss: 0.2903 - acc: 0.8544 - val_loss: 0.2807 - val_acc: 0.8667\n",
      "Epoch 38/128\n",
      "1360/1360 [==============================] - 1s 439us/step - loss: 0.2796 - acc: 0.8537 - val_loss: 0.2854 - val_acc: 0.8667\n",
      "Epoch 39/128\n",
      "1360/1360 [==============================] - 1s 446us/step - loss: 0.2877 - acc: 0.8551 - val_loss: 0.2755 - val_acc: 0.8542\n",
      "Epoch 40/128\n",
      "1360/1360 [==============================] - 1s 468us/step - loss: 0.2840 - acc: 0.8581 - val_loss: 0.2929 - val_acc: 0.8417\n",
      "Epoch 41/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.2830 - acc: 0.8515 - val_loss: 0.2872 - val_acc: 0.8542\n",
      "Epoch 42/128\n",
      "1360/1360 [==============================] - 1s 483us/step - loss: 0.2881 - acc: 0.8559 - val_loss: 0.3741 - val_acc: 0.8583\n",
      "Epoch 43/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.3214 - acc: 0.8419 - val_loss: 0.3500 - val_acc: 0.8500\n",
      "Epoch 44/128\n",
      "1360/1360 [==============================] - 1s 446us/step - loss: 0.3005 - acc: 0.8610 - val_loss: 0.3719 - val_acc: 0.8750\n",
      "Epoch 45/128\n",
      "1360/1360 [==============================] - 1s 507us/step - loss: 0.3150 - acc: 0.8471 - val_loss: 0.3570 - val_acc: 0.8292\n",
      "Epoch 46/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.2968 - acc: 0.8559 - val_loss: 0.2992 - val_acc: 0.8417\n",
      "Epoch 47/128\n",
      "1360/1360 [==============================] - 1s 442us/step - loss: 0.3064 - acc: 0.8574 - val_loss: 0.3525 - val_acc: 0.8542\n",
      "Epoch 48/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.3070 - acc: 0.8625 - val_loss: 0.3004 - val_acc: 0.8583\n",
      "Epoch 49/128\n",
      "1360/1360 [==============================] - 1s 554us/step - loss: 0.2778 - acc: 0.8610 - val_loss: 0.3229 - val_acc: 0.8292\n",
      "Epoch 50/128\n",
      "1360/1360 [==============================] - 1s 554us/step - loss: 0.2874 - acc: 0.8485 - val_loss: 0.2908 - val_acc: 0.8500\n",
      "Epoch 51/128\n",
      "1360/1360 [==============================] - 1s 570us/step - loss: 0.2741 - acc: 0.8603 - val_loss: 0.3036 - val_acc: 0.8417\n",
      "Epoch 52/128\n",
      "1360/1360 [==============================] - 1s 583us/step - loss: 0.2761 - acc: 0.8566 - val_loss: 0.2840 - val_acc: 0.8542\n",
      "Epoch 53/128\n",
      "1360/1360 [==============================] - 1s 652us/step - loss: 0.2742 - acc: 0.8566 - val_loss: 0.3171 - val_acc: 0.8708\n",
      "Epoch 54/128\n",
      "1360/1360 [==============================] - 1s 559us/step - loss: 0.2788 - acc: 0.8596 - val_loss: 0.2795 - val_acc: 0.8542\n",
      "Epoch 55/128\n",
      "1360/1360 [==============================] - 1s 527us/step - loss: 0.2734 - acc: 0.8559 - val_loss: 0.2914 - val_acc: 0.8542\n",
      "Epoch 56/128\n",
      "1360/1360 [==============================] - 1s 738us/step - loss: 0.2681 - acc: 0.8596 - val_loss: 0.2895 - val_acc: 0.8542\n",
      "Epoch 57/128\n",
      "1360/1360 [==============================] - 1s 517us/step - loss: 0.2710 - acc: 0.8581 - val_loss: 0.2863 - val_acc: 0.8667\n",
      "Epoch 58/128\n",
      "1360/1360 [==============================] - 1s 476us/step - loss: 0.2683 - acc: 0.8610 - val_loss: 0.3143 - val_acc: 0.8417\n",
      "Epoch 59/128\n",
      "1360/1360 [==============================] - 1s 628us/step - loss: 0.2987 - acc: 0.8500 - val_loss: 0.2838 - val_acc: 0.8708\n",
      "Epoch 60/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360/1360 [==============================] - 1s 838us/step - loss: 0.2723 - acc: 0.8574 - val_loss: 0.3055 - val_acc: 0.8625\n",
      "Epoch 61/128\n",
      "1360/1360 [==============================] - 1s 673us/step - loss: 0.2899 - acc: 0.8544 - val_loss: 0.2982 - val_acc: 0.8708\n",
      "Epoch 62/128\n",
      "1360/1360 [==============================] - 1s 456us/step - loss: 0.2802 - acc: 0.8559 - val_loss: 0.2859 - val_acc: 0.8333\n",
      "Epoch 63/128\n",
      "1360/1360 [==============================] - 1s 559us/step - loss: 0.3050 - acc: 0.8529 - val_loss: 0.3005 - val_acc: 0.8458\n",
      "Epoch 64/128\n",
      "1360/1360 [==============================] - 1s 579us/step - loss: 0.2725 - acc: 0.8574 - val_loss: 0.3021 - val_acc: 0.8500\n",
      "Epoch 65/128\n",
      "1360/1360 [==============================] - 1s 531us/step - loss: 0.2707 - acc: 0.8625 - val_loss: 0.3411 - val_acc: 0.8500\n",
      "Epoch 66/128\n",
      "1360/1360 [==============================] - 1s 527us/step - loss: 0.2736 - acc: 0.8676 - val_loss: 0.2933 - val_acc: 0.8583\n",
      "Epoch 67/128\n",
      "1360/1360 [==============================] - 1s 521us/step - loss: 0.2731 - acc: 0.8647 - val_loss: 0.3179 - val_acc: 0.8500\n",
      "Epoch 68/128\n",
      "1360/1360 [==============================] - 1s 546us/step - loss: 0.2621 - acc: 0.8618 - val_loss: 0.3015 - val_acc: 0.8542\n",
      "Epoch 69/128\n",
      "1360/1360 [==============================] - 1s 579us/step - loss: 0.2669 - acc: 0.8676 - val_loss: 0.3012 - val_acc: 0.8708\n",
      "Epoch 70/128\n",
      "1360/1360 [==============================] - 1s 521us/step - loss: 0.2671 - acc: 0.8654 - val_loss: 0.2987 - val_acc: 0.8583\n",
      "Epoch 71/128\n",
      "1360/1360 [==============================] - 1s 531us/step - loss: 0.2636 - acc: 0.8588 - val_loss: 0.2885 - val_acc: 0.8667\n",
      "Epoch 72/128\n",
      "1360/1360 [==============================] - 1s 545us/step - loss: 0.2571 - acc: 0.8640 - val_loss: 0.2906 - val_acc: 0.8750\n",
      "Epoch 73/128\n",
      "1360/1360 [==============================] - 1s 493us/step - loss: 0.2671 - acc: 0.8625 - val_loss: 0.3042 - val_acc: 0.8667\n",
      "Epoch 74/128\n",
      "1360/1360 [==============================] - 1s 478us/step - loss: 0.2606 - acc: 0.8691 - val_loss: 0.3191 - val_acc: 0.8417\n",
      "Epoch 75/128\n",
      "1360/1360 [==============================] - 1s 539us/step - loss: 0.2644 - acc: 0.8640 - val_loss: 0.3467 - val_acc: 0.8417\n",
      "Epoch 76/128\n",
      "1360/1360 [==============================] - 1s 490us/step - loss: 0.2560 - acc: 0.8676 - val_loss: 0.3147 - val_acc: 0.8625\n",
      "Epoch 77/128\n",
      "1360/1360 [==============================] - 1s 620us/step - loss: 0.2631 - acc: 0.8559 - val_loss: 0.3269 - val_acc: 0.8333\n",
      "Epoch 78/128\n",
      "1360/1360 [==============================] - 1s 589us/step - loss: 0.2770 - acc: 0.8625 - val_loss: 0.3056 - val_acc: 0.8750\n",
      "Epoch 79/128\n",
      "1360/1360 [==============================] - 1s 494us/step - loss: 0.2681 - acc: 0.8596 - val_loss: 0.3117 - val_acc: 0.8583\n",
      "Epoch 80/128\n",
      "1360/1360 [==============================] - 1s 472us/step - loss: 0.2572 - acc: 0.8654 - val_loss: 0.3346 - val_acc: 0.8542\n",
      "Epoch 81/128\n",
      "1360/1360 [==============================] - 1s 417us/step - loss: 0.2616 - acc: 0.8662 - val_loss: 0.3360 - val_acc: 0.8625\n",
      "Epoch 82/128\n",
      "1360/1360 [==============================] - 1s 458us/step - loss: 0.2558 - acc: 0.8721 - val_loss: 0.3397 - val_acc: 0.8292\n",
      "Epoch 83/128\n",
      "1360/1360 [==============================] - 1s 399us/step - loss: 0.2608 - acc: 0.8699 - val_loss: 0.3256 - val_acc: 0.8458\n",
      "Epoch 84/128\n",
      "1360/1360 [==============================] - 1s 424us/step - loss: 0.2677 - acc: 0.8581 - val_loss: 0.2992 - val_acc: 0.8625\n",
      "Epoch 85/128\n",
      "1360/1360 [==============================] - 1s 491us/step - loss: 0.2617 - acc: 0.8610 - val_loss: 0.3479 - val_acc: 0.8250\n",
      "Epoch 86/128\n",
      "1360/1360 [==============================] - 1s 528us/step - loss: 0.2747 - acc: 0.8618 - val_loss: 0.2842 - val_acc: 0.8542\n",
      "Epoch 87/128\n",
      "1360/1360 [==============================] - 1s 628us/step - loss: 0.2619 - acc: 0.8647 - val_loss: 0.3035 - val_acc: 0.8792\n",
      "Epoch 88/128\n",
      "1360/1360 [==============================] - 1s 614us/step - loss: 0.2546 - acc: 0.8699 - val_loss: 0.2980 - val_acc: 0.8583\n",
      "Epoch 89/128\n",
      "1360/1360 [==============================] - 1s 509us/step - loss: 0.2457 - acc: 0.8691 - val_loss: 0.2956 - val_acc: 0.8750\n",
      "Epoch 90/128\n",
      "1360/1360 [==============================] - 1s 424us/step - loss: 0.2500 - acc: 0.8706 - val_loss: 0.3157 - val_acc: 0.8667\n",
      "Epoch 91/128\n",
      "1360/1360 [==============================] - 1s 481us/step - loss: 0.2666 - acc: 0.8625 - val_loss: 0.3270 - val_acc: 0.8375\n",
      "Epoch 92/128\n",
      "1360/1360 [==============================] - 1s 479us/step - loss: 0.2532 - acc: 0.8721 - val_loss: 0.3052 - val_acc: 0.8583\n",
      "Epoch 93/128\n",
      "1360/1360 [==============================] - 1s 534us/step - loss: 0.2530 - acc: 0.8713 - val_loss: 0.3323 - val_acc: 0.8500\n",
      "Epoch 94/128\n",
      "1360/1360 [==============================] - 1s 484us/step - loss: 0.2486 - acc: 0.8713 - val_loss: 0.3399 - val_acc: 0.8458\n",
      "Epoch 95/128\n",
      "1360/1360 [==============================] - 1s 506us/step - loss: 0.2666 - acc: 0.8669 - val_loss: 0.3563 - val_acc: 0.8375\n",
      "Epoch 96/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: 0.2504 - acc: 0.8772 - val_loss: 0.3825 - val_acc: 0.8500\n",
      "Epoch 97/128\n",
      "1360/1360 [==============================] - 1s 426us/step - loss: 0.2698 - acc: 0.8654 - val_loss: 0.3664 - val_acc: 0.8625\n",
      "Epoch 98/128\n",
      "1360/1360 [==============================] - 1s 422us/step - loss: 0.2722 - acc: 0.8662 - val_loss: 0.3156 - val_acc: 0.8375\n",
      "Epoch 99/128\n",
      "1360/1360 [==============================] - 1s 510us/step - loss: 0.2548 - acc: 0.8625 - val_loss: 0.3029 - val_acc: 0.8500\n",
      "Epoch 100/128\n",
      "1360/1360 [==============================] - 1s 474us/step - loss: 0.2429 - acc: 0.8735 - val_loss: 0.3351 - val_acc: 0.8458\n",
      "Epoch 101/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.2426 - acc: 0.8706 - val_loss: 0.3329 - val_acc: 0.8625\n",
      "Epoch 102/128\n",
      "1360/1360 [==============================] - 1s 607us/step - loss: 0.2455 - acc: 0.8765 - val_loss: 0.2942 - val_acc: 0.8667\n",
      "Epoch 103/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: 0.2475 - acc: 0.8684 - val_loss: 0.3255 - val_acc: 0.8625\n",
      "Epoch 104/128\n",
      "1360/1360 [==============================] - 1s 523us/step - loss: 0.2349 - acc: 0.8765 - val_loss: 0.3336 - val_acc: 0.8667\n",
      "Epoch 105/128\n",
      "1360/1360 [==============================] - 1s 539us/step - loss: 0.2422 - acc: 0.8765 - val_loss: 0.3461 - val_acc: 0.8458\n",
      "Epoch 106/128\n",
      "1360/1360 [==============================] - 1s 445us/step - loss: 0.2551 - acc: 0.8735 - val_loss: 0.3128 - val_acc: 0.8708\n",
      "Epoch 107/128\n",
      "1360/1360 [==============================] - 1s 486us/step - loss: 0.2407 - acc: 0.8728 - val_loss: 0.3414 - val_acc: 0.8500\n",
      "Epoch 108/128\n",
      "1360/1360 [==============================] - 1s 480us/step - loss: 0.2400 - acc: 0.8809 - val_loss: 0.3482 - val_acc: 0.8417\n",
      "Epoch 109/128\n",
      "1360/1360 [==============================] - 1s 501us/step - loss: 0.2451 - acc: 0.8706 - val_loss: 0.3595 - val_acc: 0.8500\n",
      "Epoch 110/128\n",
      "1360/1360 [==============================] - 1s 436us/step - loss: 0.2390 - acc: 0.8750 - val_loss: 0.3265 - val_acc: 0.8667\n",
      "Epoch 111/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.2437 - acc: 0.8699 - val_loss: 0.3622 - val_acc: 0.8625\n",
      "Epoch 112/128\n",
      "1360/1360 [==============================] - 1s 448us/step - loss: 0.2929 - acc: 0.8632 - val_loss: 0.4125 - val_acc: 0.8250\n",
      "Epoch 113/128\n",
      "1360/1360 [==============================] - 1s 442us/step - loss: 0.2886 - acc: 0.8684 - val_loss: 0.3705 - val_acc: 0.8583\n",
      "Epoch 114/128\n",
      "1360/1360 [==============================] - 1s 426us/step - loss: 0.2697 - acc: 0.8640 - val_loss: 0.3850 - val_acc: 0.8583\n",
      "Epoch 115/128\n",
      "1360/1360 [==============================] - 1s 532us/step - loss: 0.2601 - acc: 0.8743 - val_loss: 0.3863 - val_acc: 0.8583\n",
      "Epoch 116/128\n",
      "1360/1360 [==============================] - 1s 436us/step - loss: 0.2665 - acc: 0.8676 - val_loss: 0.4708 - val_acc: 0.8417\n",
      "Epoch 117/128\n",
      "1360/1360 [==============================] - 1s 482us/step - loss: 0.2838 - acc: 0.8596 - val_loss: 0.4098 - val_acc: 0.8375\n",
      "Epoch 118/128\n",
      "1360/1360 [==============================] - 1s 537us/step - loss: 0.2622 - acc: 0.8728 - val_loss: 0.4114 - val_acc: 0.8375\n",
      "Epoch 119/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360/1360 [==============================] - 1s 538us/step - loss: 0.2612 - acc: 0.8824 - val_loss: 0.4212 - val_acc: 0.8417\n",
      "Epoch 120/128\n",
      "1360/1360 [==============================] - 1s 651us/step - loss: 0.2601 - acc: 0.8765 - val_loss: 0.4049 - val_acc: 0.8542\n",
      "Epoch 121/128\n",
      "1360/1360 [==============================] - 1s 457us/step - loss: 0.2618 - acc: 0.8779 - val_loss: 0.3725 - val_acc: 0.8583\n",
      "Epoch 122/128\n",
      "1360/1360 [==============================] - 1s 462us/step - loss: 0.2631 - acc: 0.8735 - val_loss: 0.3758 - val_acc: 0.8708\n",
      "Epoch 123/128\n",
      "1360/1360 [==============================] - 1s 571us/step - loss: 0.2552 - acc: 0.8743 - val_loss: 0.4394 - val_acc: 0.8458\n",
      "Epoch 124/128\n",
      "1360/1360 [==============================] - 1s 542us/step - loss: 0.2543 - acc: 0.8735 - val_loss: 0.4181 - val_acc: 0.8625\n",
      "Epoch 125/128\n",
      "1360/1360 [==============================] - 1s 466us/step - loss: 0.2525 - acc: 0.8765 - val_loss: 0.4695 - val_acc: 0.8500\n",
      "Epoch 126/128\n",
      "1360/1360 [==============================] - 1s 423us/step - loss: 0.2552 - acc: 0.8765 - val_loss: 0.4408 - val_acc: 0.8542\n",
      "Epoch 127/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.2797 - acc: 0.8691 - val_loss: 0.4101 - val_acc: 0.8458\n",
      "Epoch 128/128\n",
      "1360/1360 [==============================] - 1s 455us/step - loss: 0.2574 - acc: 0.8721 - val_loss: 0.3937 - val_acc: 0.8708\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(150,  activation='relu', input_shape=(12,)))\n",
    "#m.add(Dense(150,  activation='relu')) \n",
    "m.add(Dense(150,  activation='relu'))\n",
    "m.add(Dense(150,  activation='relu'))\n",
    "m.add(Dense(50,  activation='relu'))\n",
    "m.add(Dense(2,  activation='sigmoid'))\n",
    "m.compile(loss='categorical_crossentropy', optimizer = Adam(), metrics=['accuracy'])\n",
    "\n",
    "history = m.fit(X_train, y_train, batch_size=10, epochs=128, verbose=1, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 141us/step\n",
      "Précision New features: 0.87\n"
     ]
    }
   ],
   "source": [
    "accuracy = m.evaluate(X_test, y_test)[1]\n",
    "print(\"Précision New features: %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We got a precision of 87%, which is pretty better than the precision of the last year (45% according to our test and 80% according to their report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply PCA now to reduce the dimension to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca3 = PCA(n_components=3)\n",
    "\n",
    "# On entraîne notre modèle (fit) sur les données\n",
    "model_pca3.fit(X)\n",
    "\n",
    "# On applique le résultat sur nos données :\n",
    "X_reduced3 = model_pca3.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.85\n",
    "l = len(y)\n",
    "X_train = X_reduced3[:int(l*training_ratio)]\n",
    "X_test = X_reduced3[int(l*training_ratio):]\n",
    "y_train = y[:int(l*training_ratio)]/2\n",
    "y_test = y[int(l*training_ratio):]/2\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train.astype(int))\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1360 samples, validate on 240 samples\n",
      "Epoch 1/128\n",
      "1360/1360 [==============================] - 5s 4ms/step - loss: 0.5167 - acc: 0.7728 - val_loss: 0.5023 - val_acc: 0.7958\n",
      "Epoch 2/128\n",
      "1360/1360 [==============================] - 1s 544us/step - loss: 0.4741 - acc: 0.7853 - val_loss: 0.5195 - val_acc: 0.8000\n",
      "Epoch 3/128\n",
      "1360/1360 [==============================] - 1s 528us/step - loss: 0.4495 - acc: 0.7853 - val_loss: 0.5383 - val_acc: 0.7958\n",
      "Epoch 4/128\n",
      "1360/1360 [==============================] - 1s 506us/step - loss: 0.4670 - acc: 0.7794 - val_loss: 0.4729 - val_acc: 0.7875\n",
      "Epoch 5/128\n",
      "1360/1360 [==============================] - 1s 461us/step - loss: 0.4355 - acc: 0.7846 - val_loss: 0.4522 - val_acc: 0.8000\n",
      "Epoch 6/128\n",
      "1360/1360 [==============================] - 1s 520us/step - loss: 0.4412 - acc: 0.7875 - val_loss: 0.4740 - val_acc: 0.7833\n",
      "Epoch 7/128\n",
      "1360/1360 [==============================] - 1s 470us/step - loss: 0.4512 - acc: 0.7743 - val_loss: 0.4375 - val_acc: 0.7750\n",
      "Epoch 8/128\n",
      "1360/1360 [==============================] - 1s 487us/step - loss: 0.4389 - acc: 0.7772 - val_loss: 0.4076 - val_acc: 0.7917\n",
      "Epoch 9/128\n",
      "1360/1360 [==============================] - 1s 480us/step - loss: 0.4118 - acc: 0.7853 - val_loss: 0.4636 - val_acc: 0.7917\n",
      "Epoch 10/128\n",
      "1360/1360 [==============================] - 1s 504us/step - loss: 0.4091 - acc: 0.7831 - val_loss: 0.4475 - val_acc: 0.7875\n",
      "Epoch 11/128\n",
      "1360/1360 [==============================] - 1s 469us/step - loss: 0.4176 - acc: 0.7904 - val_loss: 0.4639 - val_acc: 0.7917\n",
      "Epoch 12/128\n",
      "1360/1360 [==============================] - 1s 531us/step - loss: 0.4202 - acc: 0.7860 - val_loss: 0.4707 - val_acc: 0.7833\n",
      "Epoch 13/128\n",
      "1360/1360 [==============================] - 1s 499us/step - loss: 0.4401 - acc: 0.7941 - val_loss: 0.4797 - val_acc: 0.7917\n",
      "Epoch 14/128\n",
      "1360/1360 [==============================] - 1s 523us/step - loss: 0.4281 - acc: 0.7831 - val_loss: 0.5003 - val_acc: 0.7958\n",
      "Epoch 15/128\n",
      "1360/1360 [==============================] - 1s 511us/step - loss: 0.4436 - acc: 0.7794 - val_loss: 0.4657 - val_acc: 0.7792\n",
      "Epoch 16/128\n",
      "1360/1360 [==============================] - 1s 526us/step - loss: 0.4132 - acc: 0.7875 - val_loss: 0.3860 - val_acc: 0.7833\n",
      "Epoch 17/128\n",
      "1360/1360 [==============================] - 1s 524us/step - loss: 0.3983 - acc: 0.7919 - val_loss: 0.4476 - val_acc: 0.7875\n",
      "Epoch 18/128\n",
      "1360/1360 [==============================] - 1s 510us/step - loss: 0.3839 - acc: 0.7904 - val_loss: 0.4578 - val_acc: 0.7833\n",
      "Epoch 19/128\n",
      "1360/1360 [==============================] - 1s 456us/step - loss: 0.4214 - acc: 0.7919 - val_loss: 0.3909 - val_acc: 0.7750\n",
      "Epoch 20/128\n",
      "1360/1360 [==============================] - 1s 483us/step - loss: 0.4095 - acc: 0.7772 - val_loss: 0.4165 - val_acc: 0.7833\n",
      "Epoch 21/128\n",
      "1360/1360 [==============================] - 1s 481us/step - loss: 0.3886 - acc: 0.7846 - val_loss: 0.4068 - val_acc: 0.7667\n",
      "Epoch 22/128\n",
      "1360/1360 [==============================] - 1s 472us/step - loss: 0.3910 - acc: 0.7912 - val_loss: 0.4567 - val_acc: 0.7875\n",
      "Epoch 23/128\n",
      "1360/1360 [==============================] - 1s 485us/step - loss: 0.3985 - acc: 0.7941 - val_loss: 0.4621 - val_acc: 0.7917\n",
      "Epoch 24/128\n",
      "1360/1360 [==============================] - 1s 486us/step - loss: 0.4016 - acc: 0.7941 - val_loss: 0.4427 - val_acc: 0.7958\n",
      "Epoch 25/128\n",
      "1360/1360 [==============================] - 1s 467us/step - loss: 0.4254 - acc: 0.7625 - val_loss: 0.4129 - val_acc: 0.7667\n",
      "Epoch 26/128\n",
      "1360/1360 [==============================] - 1s 485us/step - loss: 0.4335 - acc: 0.7706 - val_loss: 0.3815 - val_acc: 0.7792\n",
      "Epoch 27/128\n",
      "1360/1360 [==============================] - 1s 475us/step - loss: 0.4391 - acc: 0.7919 - val_loss: 0.3965 - val_acc: 0.7833\n",
      "Epoch 28/128\n",
      "1360/1360 [==============================] - 1s 509us/step - loss: 0.4044 - acc: 0.7860 - val_loss: 0.3830 - val_acc: 0.7833\n",
      "Epoch 29/128\n",
      "1360/1360 [==============================] - 1s 584us/step - loss: 0.3887 - acc: 0.7868 - val_loss: 0.3912 - val_acc: 0.7875\n",
      "Epoch 30/128\n",
      "1360/1360 [==============================] - 1s 566us/step - loss: 0.3891 - acc: 0.7824 - val_loss: 0.3923 - val_acc: 0.7792\n",
      "Epoch 31/128\n",
      "1360/1360 [==============================] - 1s 491us/step - loss: 0.3821 - acc: 0.7926 - val_loss: 0.3832 - val_acc: 0.7792\n",
      "Epoch 32/128\n",
      "1360/1360 [==============================] - 1s 533us/step - loss: 0.3816 - acc: 0.7890 - val_loss: 0.3816 - val_acc: 0.8000\n",
      "Epoch 33/128\n",
      "1360/1360 [==============================] - 1s 491us/step - loss: 0.3870 - acc: 0.7926 - val_loss: 0.3851 - val_acc: 0.7708\n",
      "Epoch 34/128\n",
      "1360/1360 [==============================] - 1s 463us/step - loss: 0.3729 - acc: 0.7934 - val_loss: 0.4435 - val_acc: 0.7833\n",
      "Epoch 35/128\n",
      "1360/1360 [==============================] - 1s 504us/step - loss: 0.3698 - acc: 0.7956 - val_loss: 0.4315 - val_acc: 0.7875\n",
      "Epoch 36/128\n",
      "1360/1360 [==============================] - 1s 508us/step - loss: 0.3743 - acc: 0.7897 - val_loss: 0.4659 - val_acc: 0.7833\n",
      "Epoch 37/128\n",
      "1360/1360 [==============================] - 1s 478us/step - loss: 0.3874 - acc: 0.7912 - val_loss: 0.4020 - val_acc: 0.7875\n",
      "Epoch 38/128\n",
      "1360/1360 [==============================] - 1s 491us/step - loss: 0.3862 - acc: 0.7978 - val_loss: 0.3939 - val_acc: 0.7833\n",
      "Epoch 39/128\n",
      "1360/1360 [==============================] - 1s 492us/step - loss: 0.3868 - acc: 0.7985 - val_loss: 0.3919 - val_acc: 0.7917\n",
      "Epoch 40/128\n",
      "1360/1360 [==============================] - 1s 478us/step - loss: 0.3784 - acc: 0.8074 - val_loss: 0.3908 - val_acc: 0.7750\n",
      "Epoch 41/128\n",
      "1360/1360 [==============================] - 1s 515us/step - loss: 0.3723 - acc: 0.8007 - val_loss: 0.3805 - val_acc: 0.7917\n",
      "Epoch 42/128\n",
      "1360/1360 [==============================] - 1s 490us/step - loss: 0.3738 - acc: 0.8044 - val_loss: 0.3799 - val_acc: 0.7958\n",
      "Epoch 43/128\n",
      "1360/1360 [==============================] - 1s 506us/step - loss: 0.3713 - acc: 0.8037 - val_loss: 0.3715 - val_acc: 0.8125\n",
      "Epoch 44/128\n",
      "1360/1360 [==============================] - 1s 508us/step - loss: 0.3693 - acc: 0.7971 - val_loss: 0.3694 - val_acc: 0.8042\n",
      "Epoch 45/128\n",
      "1360/1360 [==============================] - 1s 515us/step - loss: 0.3690 - acc: 0.8029 - val_loss: 0.3987 - val_acc: 0.7750\n",
      "Epoch 46/128\n",
      "1360/1360 [==============================] - 1s 515us/step - loss: 0.3683 - acc: 0.8015 - val_loss: 0.3981 - val_acc: 0.8083\n",
      "Epoch 47/128\n",
      "1360/1360 [==============================] - 1s 549us/step - loss: 0.4136 - acc: 0.8044 - val_loss: 0.4989 - val_acc: 0.8083\n",
      "Epoch 48/128\n",
      "1360/1360 [==============================] - 1s 547us/step - loss: 0.3976 - acc: 0.8059 - val_loss: 0.4071 - val_acc: 0.8042\n",
      "Epoch 49/128\n",
      "1360/1360 [==============================] - 1s 525us/step - loss: 0.3994 - acc: 0.7971 - val_loss: 0.3859 - val_acc: 0.7958\n",
      "Epoch 50/128\n",
      "1360/1360 [==============================] - 1s 532us/step - loss: 0.3756 - acc: 0.8022 - val_loss: 0.3765 - val_acc: 0.7917\n",
      "Epoch 51/128\n",
      "1360/1360 [==============================] - 1s 474us/step - loss: 0.3766 - acc: 0.8015 - val_loss: 0.4048 - val_acc: 0.7917\n",
      "Epoch 52/128\n",
      "1360/1360 [==============================] - 1s 483us/step - loss: 0.3764 - acc: 0.8022 - val_loss: 0.3846 - val_acc: 0.8042\n",
      "Epoch 53/128\n",
      "1360/1360 [==============================] - 1s 471us/step - loss: 0.3612 - acc: 0.8044 - val_loss: 0.4172 - val_acc: 0.8000\n",
      "Epoch 54/128\n",
      "1360/1360 [==============================] - 1s 526us/step - loss: 0.3651 - acc: 0.8059 - val_loss: 0.4021 - val_acc: 0.7917\n",
      "Epoch 55/128\n",
      "1360/1360 [==============================] - 1s 517us/step - loss: 0.3801 - acc: 0.8029 - val_loss: 0.3860 - val_acc: 0.8167\n",
      "Epoch 56/128\n",
      "1360/1360 [==============================] - 1s 485us/step - loss: 0.3685 - acc: 0.7971 - val_loss: 0.3836 - val_acc: 0.8167\n",
      "Epoch 57/128\n",
      "1360/1360 [==============================] - 1s 516us/step - loss: 0.3658 - acc: 0.8000 - val_loss: 0.3841 - val_acc: 0.8208\n",
      "Epoch 58/128\n",
      "1360/1360 [==============================] - 1s 527us/step - loss: 0.3629 - acc: 0.8007 - val_loss: 0.3739 - val_acc: 0.8000\n",
      "Epoch 59/128\n",
      "1360/1360 [==============================] - 1s 530us/step - loss: 0.3584 - acc: 0.8044 - val_loss: 0.3812 - val_acc: 0.8000\n",
      "Epoch 60/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360/1360 [==============================] - 1s 468us/step - loss: 0.3521 - acc: 0.8044 - val_loss: 0.3912 - val_acc: 0.7958\n",
      "Epoch 61/128\n",
      "1360/1360 [==============================] - 1s 445us/step - loss: 0.3523 - acc: 0.8044 - val_loss: 0.3719 - val_acc: 0.8167\n",
      "Epoch 62/128\n",
      "1360/1360 [==============================] - 1s 434us/step - loss: 0.3560 - acc: 0.8029 - val_loss: 0.3868 - val_acc: 0.8000\n",
      "Epoch 63/128\n",
      "1360/1360 [==============================] - 1s 451us/step - loss: 0.3643 - acc: 0.8059 - val_loss: 0.4487 - val_acc: 0.8083\n",
      "Epoch 64/128\n",
      "1360/1360 [==============================] - 1s 435us/step - loss: 0.3723 - acc: 0.8051 - val_loss: 0.4553 - val_acc: 0.8000\n",
      "Epoch 65/128\n",
      "1360/1360 [==============================] - 1s 443us/step - loss: 0.3653 - acc: 0.8066 - val_loss: 0.4521 - val_acc: 0.8042\n",
      "Epoch 66/128\n",
      "1360/1360 [==============================] - 1s 460us/step - loss: 0.3668 - acc: 0.8051 - val_loss: 0.4696 - val_acc: 0.8000\n",
      "Epoch 67/128\n",
      "1360/1360 [==============================] - 1s 465us/step - loss: 0.3495 - acc: 0.8066 - val_loss: 0.3951 - val_acc: 0.8000\n",
      "Epoch 68/128\n",
      "1360/1360 [==============================] - 1s 447us/step - loss: 0.3589 - acc: 0.8096 - val_loss: 0.4181 - val_acc: 0.8125\n",
      "Epoch 69/128\n",
      "1360/1360 [==============================] - 1s 455us/step - loss: 0.3483 - acc: 0.8074 - val_loss: 0.4011 - val_acc: 0.8000\n",
      "Epoch 70/128\n",
      "1360/1360 [==============================] - 1s 442us/step - loss: 0.3408 - acc: 0.8103 - val_loss: 0.4807 - val_acc: 0.8000\n",
      "Epoch 71/128\n",
      "1360/1360 [==============================] - 1s 450us/step - loss: 0.3545 - acc: 0.8066 - val_loss: 0.4039 - val_acc: 0.8042\n",
      "Epoch 72/128\n",
      "1360/1360 [==============================] - 1s 479us/step - loss: 0.3384 - acc: 0.8059 - val_loss: 0.4128 - val_acc: 0.7917\n",
      "Epoch 73/128\n",
      "1360/1360 [==============================] - 1s 448us/step - loss: 0.3410 - acc: 0.8096 - val_loss: 0.4849 - val_acc: 0.8000\n",
      "Epoch 74/128\n",
      "1360/1360 [==============================] - 1s 518us/step - loss: 0.3454 - acc: 0.8051 - val_loss: 0.4663 - val_acc: 0.8000\n",
      "Epoch 75/128\n",
      "1360/1360 [==============================] - 1s 519us/step - loss: 0.3330 - acc: 0.8081 - val_loss: 0.4578 - val_acc: 0.8167\n",
      "Epoch 76/128\n",
      "1360/1360 [==============================] - 1s 452us/step - loss: 0.3300 - acc: 0.8125 - val_loss: 0.4131 - val_acc: 0.7958\n",
      "Epoch 77/128\n",
      "1360/1360 [==============================] - 1s 446us/step - loss: 0.3310 - acc: 0.8110 - val_loss: 0.4580 - val_acc: 0.7958\n",
      "Epoch 78/128\n",
      "1360/1360 [==============================] - 1s 475us/step - loss: 0.3532 - acc: 0.8059 - val_loss: 0.4855 - val_acc: 0.8000\n",
      "Epoch 79/128\n",
      "1360/1360 [==============================] - 1s 453us/step - loss: 0.3586 - acc: 0.8081 - val_loss: 0.4910 - val_acc: 0.8083\n",
      "Epoch 80/128\n",
      "1360/1360 [==============================] - 1s 458us/step - loss: 0.3526 - acc: 0.8154 - val_loss: 0.4621 - val_acc: 0.8125\n",
      "Epoch 81/128\n",
      "1360/1360 [==============================] - 1s 449us/step - loss: 0.3304 - acc: 0.8118 - val_loss: 0.5085 - val_acc: 0.8000\n",
      "Epoch 82/128\n",
      "1360/1360 [==============================] - 1s 468us/step - loss: 0.3510 - acc: 0.8103 - val_loss: 0.4037 - val_acc: 0.8000\n",
      "Epoch 83/128\n",
      "1360/1360 [==============================] - 1s 446us/step - loss: 0.3321 - acc: 0.8110 - val_loss: 0.4284 - val_acc: 0.8083\n",
      "Epoch 84/128\n",
      "1360/1360 [==============================] - 1s 447us/step - loss: 0.3269 - acc: 0.8074 - val_loss: 0.4144 - val_acc: 0.7875\n",
      "Epoch 85/128\n",
      "1360/1360 [==============================] - 1s 445us/step - loss: 0.3247 - acc: 0.8147 - val_loss: 0.4489 - val_acc: 0.7792\n",
      "Epoch 86/128\n",
      "1360/1360 [==============================] - 1s 450us/step - loss: 0.3181 - acc: 0.8184 - val_loss: 0.4953 - val_acc: 0.8042\n",
      "Epoch 87/128\n",
      "1360/1360 [==============================] - 1s 455us/step - loss: 0.3386 - acc: 0.8199 - val_loss: 0.4852 - val_acc: 0.8042\n",
      "Epoch 88/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.3380 - acc: 0.8154 - val_loss: 0.4785 - val_acc: 0.8042\n",
      "Epoch 89/128\n",
      "1360/1360 [==============================] - 1s 445us/step - loss: 0.3440 - acc: 0.8191 - val_loss: 0.4745 - val_acc: 0.7875\n",
      "Epoch 90/128\n",
      "1360/1360 [==============================] - 1s 448us/step - loss: 0.3406 - acc: 0.8110 - val_loss: 0.4973 - val_acc: 0.7667\n",
      "Epoch 91/128\n",
      "1360/1360 [==============================] - 1s 450us/step - loss: 0.3348 - acc: 0.8176 - val_loss: 0.5045 - val_acc: 0.8042\n",
      "Epoch 92/128\n",
      "1360/1360 [==============================] - 1s 467us/step - loss: 0.3375 - acc: 0.8140 - val_loss: 0.5133 - val_acc: 0.7708\n",
      "Epoch 93/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.3409 - acc: 0.8243 - val_loss: 0.5475 - val_acc: 0.7958\n",
      "Epoch 94/128\n",
      "1360/1360 [==============================] - 1s 457us/step - loss: 0.3385 - acc: 0.8191 - val_loss: 0.5049 - val_acc: 0.7833\n",
      "Epoch 95/128\n",
      "1360/1360 [==============================] - 1s 475us/step - loss: 0.3265 - acc: 0.8265 - val_loss: 0.5121 - val_acc: 0.7875\n",
      "Epoch 96/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.3284 - acc: 0.8213 - val_loss: 0.5106 - val_acc: 0.7958\n",
      "Epoch 97/128\n",
      "1360/1360 [==============================] - 1s 466us/step - loss: 0.3405 - acc: 0.8279 - val_loss: 0.5122 - val_acc: 0.8250\n",
      "Epoch 98/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.3325 - acc: 0.8213 - val_loss: 0.5288 - val_acc: 0.8083\n",
      "Epoch 99/128\n",
      "1360/1360 [==============================] - 1s 442us/step - loss: 0.3209 - acc: 0.8257 - val_loss: 0.5343 - val_acc: 0.8042\n",
      "Epoch 100/128\n",
      "1360/1360 [==============================] - 1s 468us/step - loss: 0.3286 - acc: 0.8375 - val_loss: 0.5201 - val_acc: 0.8250\n",
      "Epoch 101/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.3206 - acc: 0.8324 - val_loss: 0.5569 - val_acc: 0.8083\n",
      "Epoch 102/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.3174 - acc: 0.8272 - val_loss: 0.5493 - val_acc: 0.7958\n",
      "Epoch 103/128\n",
      "1360/1360 [==============================] - 1s 449us/step - loss: 0.2988 - acc: 0.8316 - val_loss: 0.6138 - val_acc: 0.7958\n",
      "Epoch 104/128\n",
      "1360/1360 [==============================] - 1s 451us/step - loss: 0.3236 - acc: 0.8272 - val_loss: 0.6074 - val_acc: 0.7792\n",
      "Epoch 105/128\n",
      "1360/1360 [==============================] - 1s 447us/step - loss: 0.3297 - acc: 0.8360 - val_loss: 0.5365 - val_acc: 0.8042\n",
      "Epoch 106/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.3186 - acc: 0.8257 - val_loss: 0.5696 - val_acc: 0.8208\n",
      "Epoch 107/128\n",
      "1360/1360 [==============================] - 1s 437us/step - loss: 0.3089 - acc: 0.8382 - val_loss: 0.5673 - val_acc: 0.8125\n",
      "Epoch 108/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.3174 - acc: 0.8368 - val_loss: 0.5559 - val_acc: 0.8083\n",
      "Epoch 109/128\n",
      "1360/1360 [==============================] - 1s 446us/step - loss: 0.3069 - acc: 0.8434 - val_loss: 0.5756 - val_acc: 0.7833\n",
      "Epoch 110/128\n",
      "1360/1360 [==============================] - ETA: 0s - loss: 0.3080 - acc: 0.836 - 1s 448us/step - loss: 0.3064 - acc: 0.8353 - val_loss: 0.5880 - val_acc: 0.8042\n",
      "Epoch 111/128\n",
      "1360/1360 [==============================] - 1s 445us/step - loss: 0.3092 - acc: 0.8338 - val_loss: 0.5810 - val_acc: 0.7875\n",
      "Epoch 112/128\n",
      "1360/1360 [==============================] - 1s 439us/step - loss: 0.3051 - acc: 0.8294 - val_loss: 0.6007 - val_acc: 0.7958\n",
      "Epoch 113/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.2961 - acc: 0.8309 - val_loss: 0.6144 - val_acc: 0.7917\n",
      "Epoch 114/128\n",
      "1360/1360 [==============================] - 1s 454us/step - loss: 0.3079 - acc: 0.8331 - val_loss: 0.5798 - val_acc: 0.7917\n",
      "Epoch 115/128\n",
      "1360/1360 [==============================] - 1s 451us/step - loss: 0.3034 - acc: 0.8368 - val_loss: 0.5857 - val_acc: 0.8083\n",
      "Epoch 116/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.3017 - acc: 0.8471 - val_loss: 0.5979 - val_acc: 0.7708\n",
      "Epoch 117/128\n",
      "1360/1360 [==============================] - 1s 444us/step - loss: 0.3077 - acc: 0.8441 - val_loss: 0.5985 - val_acc: 0.8083\n",
      "Epoch 118/128\n",
      "1360/1360 [==============================] - 1s 444us/step - loss: 0.3006 - acc: 0.8368 - val_loss: 0.6353 - val_acc: 0.7667\n",
      "Epoch 119/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360/1360 [==============================] - 1s 442us/step - loss: 0.2967 - acc: 0.8338 - val_loss: 0.6269 - val_acc: 0.7833\n",
      "Epoch 120/128\n",
      "1360/1360 [==============================] - 1s 438us/step - loss: 0.3012 - acc: 0.8338 - val_loss: 0.6069 - val_acc: 0.7792\n",
      "Epoch 121/128\n",
      "1360/1360 [==============================] - 1s 432us/step - loss: 0.2959 - acc: 0.8493 - val_loss: 0.6122 - val_acc: 0.8125\n",
      "Epoch 122/128\n",
      "1360/1360 [==============================] - 1s 441us/step - loss: 0.2903 - acc: 0.8471 - val_loss: 0.6366 - val_acc: 0.7750\n",
      "Epoch 123/128\n",
      "1360/1360 [==============================] - 1s 440us/step - loss: 0.2920 - acc: 0.8412 - val_loss: 0.6335 - val_acc: 0.7833\n",
      "Epoch 124/128\n",
      "1360/1360 [==============================] - 1s 444us/step - loss: 0.2967 - acc: 0.8353 - val_loss: 0.6437 - val_acc: 0.7708\n",
      "Epoch 125/128\n",
      "1360/1360 [==============================] - ETA: 0s - loss: 0.2927 - acc: 0.835 - 1s 438us/step - loss: 0.2924 - acc: 0.8360 - val_loss: 0.6150 - val_acc: 0.7875\n",
      "Epoch 126/128\n",
      "1360/1360 [==============================] - 1s 437us/step - loss: 0.3209 - acc: 0.8294 - val_loss: 0.6275 - val_acc: 0.7792\n",
      "Epoch 127/128\n",
      "1360/1360 [==============================] - 1s 439us/step - loss: 0.2876 - acc: 0.8338 - val_loss: 0.5881 - val_acc: 0.8000\n",
      "Epoch 128/128\n",
      "1360/1360 [==============================] - 1s 436us/step - loss: 0.3077 - acc: 0.8324 - val_loss: 0.6567 - val_acc: 0.7667\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(150,  activation='relu', input_shape=(3,)))\n",
    "#m.add(Dense(150,  activation='relu')) \n",
    "m.add(Dense(150,  activation='relu'))\n",
    "m.add(Dense(150,  activation='relu'))\n",
    "m.add(Dense(50,  activation='relu'))\n",
    "m.add(Dense(2,  activation='sigmoid'))\n",
    "m.compile(loss='categorical_crossentropy', optimizer = Adam(), metrics=['accuracy'])\n",
    "\n",
    "history = m.fit(X_train, y_train, batch_size=10, epochs=128, verbose=1, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a PCA doesn't improve (actually worsens the accuracy of our model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
